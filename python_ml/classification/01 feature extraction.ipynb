{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the Inception v3 module from Tensorflow hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the graph that implements the module. We create the placeholder with the expected shape from the documentation and make a node for the features. Then we get the initializers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "img_graph = tf.Graph()\n",
    "\n",
    "with img_graph.as_default():\n",
    "    # Download module\n",
    "    module_url = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1'\n",
    "    feature_extractor = hub.Module(module_url)\n",
    "\n",
    "    # Create input placeholder\n",
    "    input_imgs = tf.placeholder(dtype=tf.float32, shape=[None, 299, 299, 3])\n",
    "\n",
    "    # A node with the features\n",
    "    imgs_features = feature_extractor(input_imgs)\n",
    "\n",
    "    # Collect initializers\n",
    "    init_op = tf.group([\n",
    "        tf.global_variables_initializer(), tf.tables_initializer()\n",
    "    ])\n",
    "\n",
    "img_graph.finalize();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the session and run our initializers. Then we can extract the features from the batch image. We should get a feature vector size of 2048."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaly there should be 280 images in the train set but somehow I got one more in the bike folder due to checkpoints from github, I tried removing them using a command in a gitignore document I created but it didn't fix it, so I figured it wasn't that important anyway.\n",
    "\n",
    "So I create an Image generator that will rescale my images and I flow it through my directory. I use the wanted target size and set batch size to the size of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 281 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\"swissroads/train\",target_size=(299,299),batch_size=281,class_mode=\"sparse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 139 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = datagen.flow_from_directory(\"swissroads/valid\",target_size=(299,299),batch_size=139,class_mode=\"sparse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_directory(\"swissroads/test\",target_size=(299,299),batch_size=50,class_mode=\"sparse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can extract my features that I can feed to the graph to get the high-level ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = train_generator[0][0]\n",
    "y_train = train_generator[0][1]\n",
    "X_valid_raw = valid_generator[0][0]\n",
    "y_valid = valid_generator[0][1]\n",
    "X_test_raw = test_generator[0][0]\n",
    "y_test = test_generator[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session\n",
    "sess = tf.Session(graph=img_graph)\n",
    "\n",
    "# Initialize it\n",
    "sess.run(init_op)\n",
    "\n",
    "# Extract features\n",
    "X_train = sess.run(imgs_features, feed_dict={input_imgs: X_train_raw})\n",
    "X_valid = sess.run(imgs_features, feed_dict={input_imgs: X_valid_raw})\n",
    "X_test = sess.run(imgs_features, feed_dict={input_imgs: X_test_raw})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape : (281, 2048) and y train shape : (281,)\n",
      "X valid shape : (139, 2048) and y valid shape : (139,)\n",
      "X test shape : (50, 2048) and y test shape : (50,)\n",
      "Raw pixels from train shape: (281, 299, 299, 3) and y train shape : (281,)\n",
      "Raw pixels from valid shape: (139, 299, 299, 3) and y test shape : (139,)\n",
      "Raw pixels from test shape: (50, 299, 299, 3) and y test shape : (50,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train shape : {} and y train shape : {}\".format(X_train.shape,y_train.shape))\n",
    "print(\"X valid shape : {} and y valid shape : {}\".format(X_valid.shape,y_valid.shape))\n",
    "print(\"X test shape : {} and y test shape : {}\".format(X_test.shape,y_test.shape))\n",
    "print(\"Raw pixels from train shape: {} and y train shape : {}\".format(X_train_raw.shape,y_train.shape))\n",
    "print(\"Raw pixels from valid shape: {} and y test shape : {}\".format(X_valid_raw.shape,y_valid.shape))\n",
    "print(\"Raw pixels from test shape: {} and y test shape : {}\".format(X_test_raw.shape,y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we got the shapes we need with the right number of image and the expected highlevel output. We can now save these values in an npz file for later use. We keep the raw pixels as well to plot images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"train_data.npz\",data = X_train, labels = y_train)\n",
    "np.savez(\"valid_data.npz\",data = X_valid, labels = y_valid)\n",
    "np.savez(\"test_data.npz\",data = X_test, labels = y_test)\n",
    "np.savez(\"raw_train.npz\",data = X_train_raw, labels = y_train)\n",
    "np.savez(\"raw_valid.npz\",data = X_valid_raw, labels = y_valid)\n",
    "np.savez(\"raw_test.npz\",data = X_test_raw, labels = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
