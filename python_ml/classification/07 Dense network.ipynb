{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. Dense Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"train_data.npz\",allow_pickle=False) as train_npz:\n",
    "    train_data = dict(train_npz.items())\n",
    "\n",
    "with np.load(\"valid_data.npz\",allow_pickle=False) as valid_npz:\n",
    "    valid_data = dict(valid_npz.items())\n",
    "\n",
    "with np.load(\"test_data.npz\",allow_pickle=False) as test_npz:\n",
    "    test_data = dict(test_npz.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = train_data.values()\n",
    "X_valid,y_valid = valid_data.values()\n",
    "X_test,y_test = test_data.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's concatenate our train and validation data to use this in our fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train,X_valid))\n",
    "y_train = np.concatenate((y_train,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our model with keras and make one dense layer to get the 6 outputs we want, I use softmax activation as it's the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 2048)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 12,294\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1d = keras.Sequential()\n",
    "model1d.add(keras.layers.Dense(units=6,activation=\"softmax\",input_dim=2048))\n",
    "model1d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we get the expected number of parameters : 2048\\*6+6 = 12294.\n",
    "\n",
    "Let's now define the training elements and an early stopping to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1d.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now fit our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 315 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 1.5419 - acc: 0.4063 - val_loss: 0.9797 - val_acc: 0.8095\n",
      "Epoch 2/100\n",
      "315/315 [==============================] - 0s 113us/step - loss: 0.7357 - acc: 0.8730 - val_loss: 0.5036 - val_acc: 0.9429\n",
      "Epoch 3/100\n",
      "315/315 [==============================] - 0s 120us/step - loss: 0.4042 - acc: 0.9238 - val_loss: 0.3321 - val_acc: 0.9429\n",
      "Epoch 4/100\n",
      "315/315 [==============================] - 0s 130us/step - loss: 0.2884 - acc: 0.9397 - val_loss: 0.2704 - val_acc: 0.9429\n",
      "Epoch 5/100\n",
      "315/315 [==============================] - 0s 109us/step - loss: 0.2241 - acc: 0.9556 - val_loss: 0.2478 - val_acc: 0.9333\n",
      "Epoch 6/100\n",
      "315/315 [==============================] - 0s 136us/step - loss: 0.1892 - acc: 0.9683 - val_loss: 0.2243 - val_acc: 0.9429\n",
      "Epoch 7/100\n",
      "315/315 [==============================] - 0s 99us/step - loss: 0.1671 - acc: 0.9714 - val_loss: 0.2144 - val_acc: 0.9333\n",
      "Epoch 8/100\n",
      "315/315 [==============================] - 0s 107us/step - loss: 0.1505 - acc: 0.9714 - val_loss: 0.2055 - val_acc: 0.9429\n",
      "Epoch 9/100\n",
      "315/315 [==============================] - 0s 94us/step - loss: 0.1331 - acc: 0.9746 - val_loss: 0.2003 - val_acc: 0.9238\n",
      "Epoch 10/100\n",
      "315/315 [==============================] - 0s 107us/step - loss: 0.1184 - acc: 0.9810 - val_loss: 0.1934 - val_acc: 0.9429\n",
      "Epoch 11/100\n",
      "315/315 [==============================] - 0s 100us/step - loss: 0.1121 - acc: 0.9810 - val_loss: 0.1877 - val_acc: 0.9429\n",
      "Epoch 12/100\n",
      "315/315 [==============================] - 0s 96us/step - loss: 0.1024 - acc: 0.9810 - val_loss: 0.1927 - val_acc: 0.9333\n",
      "Epoch 13/100\n",
      "315/315 [==============================] - 0s 112us/step - loss: 0.0921 - acc: 0.9873 - val_loss: 0.1844 - val_acc: 0.9333\n",
      "Epoch 14/100\n",
      "315/315 [==============================] - 0s 88us/step - loss: 0.0869 - acc: 0.9873 - val_loss: 0.1819 - val_acc: 0.9333\n",
      "Epoch 15/100\n",
      "315/315 [==============================] - 0s 109us/step - loss: 0.0802 - acc: 0.9873 - val_loss: 0.1829 - val_acc: 0.9333\n",
      "Epoch 16/100\n",
      "315/315 [==============================] - 0s 102us/step - loss: 0.0765 - acc: 0.9873 - val_loss: 0.1793 - val_acc: 0.9333\n",
      "Epoch 17/100\n",
      "315/315 [==============================] - 0s 122us/step - loss: 0.0691 - acc: 0.9905 - val_loss: 0.1826 - val_acc: 0.9238\n",
      "Epoch 18/100\n",
      "315/315 [==============================] - 0s 110us/step - loss: 0.0645 - acc: 0.9937 - val_loss: 0.1775 - val_acc: 0.9333\n",
      "Epoch 19/100\n",
      "315/315 [==============================] - 0s 146us/step - loss: 0.0599 - acc: 0.9937 - val_loss: 0.1777 - val_acc: 0.9333\n",
      "Epoch 20/100\n",
      "315/315 [==============================] - 0s 114us/step - loss: 0.0568 - acc: 0.9968 - val_loss: 0.1763 - val_acc: 0.9333\n",
      "Epoch 21/100\n",
      "315/315 [==============================] - 0s 128us/step - loss: 0.0547 - acc: 0.9937 - val_loss: 0.1774 - val_acc: 0.9333\n",
      "Epoch 22/100\n",
      "315/315 [==============================] - 0s 125us/step - loss: 0.0494 - acc: 0.9968 - val_loss: 0.1757 - val_acc: 0.9333\n",
      "Epoch 23/100\n",
      "315/315 [==============================] - 0s 116us/step - loss: 0.0475 - acc: 0.9968 - val_loss: 0.1765 - val_acc: 0.9333\n",
      "Epoch 24/100\n",
      "315/315 [==============================] - 0s 104us/step - loss: 0.0442 - acc: 0.9968 - val_loss: 0.1757 - val_acc: 0.9238\n",
      "Epoch 25/100\n",
      "315/315 [==============================] - 0s 87us/step - loss: 0.0421 - acc: 1.0000 - val_loss: 0.1753 - val_acc: 0.9238\n",
      "Epoch 26/100\n",
      "315/315 [==============================] - 0s 101us/step - loss: 0.0396 - acc: 1.0000 - val_loss: 0.1741 - val_acc: 0.9238\n",
      "Epoch 27/100\n",
      "315/315 [==============================] - 0s 97us/step - loss: 0.0385 - acc: 1.0000 - val_loss: 0.1761 - val_acc: 0.9333\n",
      "Epoch 28/100\n",
      "315/315 [==============================] - 0s 93us/step - loss: 0.0364 - acc: 1.0000 - val_loss: 0.1746 - val_acc: 0.9333\n",
      "Epoch 29/100\n",
      "315/315 [==============================] - 0s 89us/step - loss: 0.0346 - acc: 1.0000 - val_loss: 0.1750 - val_acc: 0.9333\n",
      "Epoch 30/100\n",
      "315/315 [==============================] - 0s 91us/step - loss: 0.0325 - acc: 1.0000 - val_loss: 0.1757 - val_acc: 0.9238\n",
      "Epoch 31/100\n",
      "315/315 [==============================] - 0s 89us/step - loss: 0.0312 - acc: 1.0000 - val_loss: 0.1752 - val_acc: 0.9143\n"
     ]
    }
   ],
   "source": [
    "history1d = model1d.fit(X_train,y_train,batch_size=32,epochs=100,validation_split=0.25,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation accuracy (last 3) : 92.4%\n"
     ]
    }
   ],
   "source": [
    "mean_val_acc1d = np.mean(history1d.history[\"val_acc\"][-3:])\n",
    "print(\"Mean validation accuracy (last 3) : {:.1f}%\".format(100*mean_val_acc1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add a hidden layer with a ReLU activation and 10 outputs to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 66        \n",
      "=================================================================\n",
      "Total params: 20,556\n",
      "Trainable params: 20,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2d = keras.Sequential()\n",
    "model2d.add(keras.layers.Dense(units=10,activation=\"relu\",input_dim=2048))\n",
    "model2d.add(keras.layers.Dense(units=6,activation=\"softmax\"))\n",
    "model2d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2d.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 315 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 1.4716 - acc: 0.4794 - val_loss: 1.0288 - val_acc: 0.6857\n",
      "Epoch 2/100\n",
      "315/315 [==============================] - 0s 117us/step - loss: 0.8413 - acc: 0.7714 - val_loss: 0.6586 - val_acc: 0.8476\n",
      "Epoch 3/100\n",
      "315/315 [==============================] - 0s 123us/step - loss: 0.5810 - acc: 0.8540 - val_loss: 0.4954 - val_acc: 0.8762\n",
      "Epoch 4/100\n",
      "315/315 [==============================] - 0s 106us/step - loss: 0.4217 - acc: 0.8667 - val_loss: 0.3996 - val_acc: 0.8857\n",
      "Epoch 5/100\n",
      "315/315 [==============================] - 0s 104us/step - loss: 0.3302 - acc: 0.9270 - val_loss: 0.3449 - val_acc: 0.9048\n",
      "Epoch 6/100\n",
      "315/315 [==============================] - 0s 107us/step - loss: 0.2645 - acc: 0.9397 - val_loss: 0.3053 - val_acc: 0.9238\n",
      "Epoch 7/100\n",
      "315/315 [==============================] - 0s 105us/step - loss: 0.2259 - acc: 0.9651 - val_loss: 0.2845 - val_acc: 0.9048\n",
      "Epoch 8/100\n",
      "315/315 [==============================] - 0s 106us/step - loss: 0.1926 - acc: 0.9619 - val_loss: 0.2670 - val_acc: 0.9238\n",
      "Epoch 9/100\n",
      "315/315 [==============================] - 0s 106us/step - loss: 0.1676 - acc: 0.9746 - val_loss: 0.2543 - val_acc: 0.9238\n",
      "Epoch 10/100\n",
      "315/315 [==============================] - 0s 107us/step - loss: 0.1508 - acc: 0.9746 - val_loss: 0.2421 - val_acc: 0.9238\n",
      "Epoch 11/100\n",
      "315/315 [==============================] - 0s 103us/step - loss: 0.1338 - acc: 0.9810 - val_loss: 0.2345 - val_acc: 0.9238\n",
      "Epoch 12/100\n",
      "315/315 [==============================] - 0s 110us/step - loss: 0.1220 - acc: 0.9714 - val_loss: 0.2265 - val_acc: 0.9238\n",
      "Epoch 13/100\n",
      "315/315 [==============================] - 0s 115us/step - loss: 0.1090 - acc: 0.9810 - val_loss: 0.2185 - val_acc: 0.9238\n",
      "Epoch 14/100\n",
      "315/315 [==============================] - 0s 110us/step - loss: 0.0970 - acc: 0.9841 - val_loss: 0.2173 - val_acc: 0.9143\n",
      "Epoch 15/100\n",
      "315/315 [==============================] - 0s 135us/step - loss: 0.0914 - acc: 0.9841 - val_loss: 0.2097 - val_acc: 0.9238\n",
      "Epoch 16/100\n",
      "315/315 [==============================] - 0s 117us/step - loss: 0.0822 - acc: 0.9841 - val_loss: 0.2054 - val_acc: 0.9143\n",
      "Epoch 17/100\n",
      "315/315 [==============================] - 0s 104us/step - loss: 0.0762 - acc: 0.9905 - val_loss: 0.2057 - val_acc: 0.9238\n",
      "Epoch 18/100\n",
      "315/315 [==============================] - 0s 119us/step - loss: 0.0709 - acc: 0.9937 - val_loss: 0.2001 - val_acc: 0.9143\n",
      "Epoch 19/100\n",
      "315/315 [==============================] - 0s 106us/step - loss: 0.0647 - acc: 0.9937 - val_loss: 0.1985 - val_acc: 0.9333\n",
      "Epoch 20/100\n",
      "315/315 [==============================] - 0s 116us/step - loss: 0.0597 - acc: 0.9968 - val_loss: 0.1987 - val_acc: 0.9143\n",
      "Epoch 21/100\n",
      "315/315 [==============================] - 0s 108us/step - loss: 0.0546 - acc: 0.9937 - val_loss: 0.1932 - val_acc: 0.9238\n",
      "Epoch 22/100\n",
      "315/315 [==============================] - 0s 104us/step - loss: 0.0502 - acc: 1.0000 - val_loss: 0.1913 - val_acc: 0.9238\n",
      "Epoch 23/100\n",
      "315/315 [==============================] - 0s 103us/step - loss: 0.0477 - acc: 0.9968 - val_loss: 0.1928 - val_acc: 0.9238\n",
      "Epoch 24/100\n",
      "315/315 [==============================] - 0s 105us/step - loss: 0.0436 - acc: 1.0000 - val_loss: 0.1902 - val_acc: 0.9143\n",
      "Epoch 25/100\n",
      "315/315 [==============================] - 0s 105us/step - loss: 0.0411 - acc: 1.0000 - val_loss: 0.1930 - val_acc: 0.9238\n",
      "Epoch 26/100\n",
      "315/315 [==============================] - 0s 108us/step - loss: 0.0386 - acc: 1.0000 - val_loss: 0.1885 - val_acc: 0.9143\n",
      "Epoch 27/100\n",
      "315/315 [==============================] - 0s 108us/step - loss: 0.0371 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9333\n",
      "Epoch 28/100\n",
      "315/315 [==============================] - 0s 115us/step - loss: 0.0336 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9238\n",
      "Epoch 29/100\n",
      "315/315 [==============================] - 0s 106us/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.1882 - val_acc: 0.9333\n",
      "Epoch 30/100\n",
      "315/315 [==============================] - 0s 105us/step - loss: 0.0296 - acc: 1.0000 - val_loss: 0.1878 - val_acc: 0.9143\n",
      "Epoch 31/100\n",
      "315/315 [==============================] - 0s 108us/step - loss: 0.0277 - acc: 1.0000 - val_loss: 0.1889 - val_acc: 0.9333\n",
      "Epoch 32/100\n",
      "315/315 [==============================] - 0s 101us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.1867 - val_acc: 0.9238\n",
      "Epoch 33/100\n",
      "315/315 [==============================] - 0s 105us/step - loss: 0.0251 - acc: 1.0000 - val_loss: 0.1907 - val_acc: 0.9238\n",
      "Epoch 34/100\n",
      "315/315 [==============================] - 0s 111us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.1889 - val_acc: 0.9333\n",
      "Epoch 35/100\n",
      "315/315 [==============================] - 0s 110us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.1882 - val_acc: 0.9333\n",
      "Epoch 36/100\n",
      "315/315 [==============================] - 0s 107us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.1871 - val_acc: 0.9333\n",
      "Epoch 37/100\n",
      "315/315 [==============================] - 0s 106us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.1876 - val_acc: 0.9238\n"
     ]
    }
   ],
   "source": [
    "history2d = model2d.fit(X_train,y_train,batch_size=32,epochs=100,validation_split=0.25,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation accuracy (last 3) : 93.0%\n"
     ]
    }
   ],
   "source": [
    "mean_val_acc2d = np.mean(history2d.history[\"val_acc\"][-3:])\n",
    "print(\"Mean validation accuracy (last 3) : {:.1f}%\".format(100*mean_val_acc2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get similar results in accuracy with 2 layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute and collect our test accuracies :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 113us/step\n",
      "50/50 [==============================] - 0s 129us/step\n"
     ]
    }
   ],
   "source": [
    "(nn1_test_loss,nn1_test_acc) = model1d.evaluate(X_test,y_test)\n",
    "(nn2_test_loss,nn2_test_acc) = model2d.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn1_test_acc = nn1_test_acc*100\n",
    "nn2_test_acc = nn2_test_acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy nn1 : 96.0%\n",
      "Test accuracy nn2 : 96.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy nn1 : {:.1f}%\".format(nn1_test_acc))\n",
    "print(\"Test accuracy nn2 : {:.1f}%\".format(nn2_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'nn1_test_acc' (float64)\n",
      "Stored 'nn2_test_acc' (float64)\n"
     ]
    }
   ],
   "source": [
    "%store nn1_test_acc\n",
    "%store nn2_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
